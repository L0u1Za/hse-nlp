{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44e6bf0",
   "metadata": {
    "cellId": "wra9nvqs6b8zv3boz3d9ok",
    "execution_id": "59711112-acee-4fe8-9641-2c1f63419230"
   },
   "source": [
    "# Глубинное обучение для текстовых данных, ФКН ВШЭ\n",
    "## Домашнее задание 4: уменьшение размеров модели\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Максимально допустимая оценка за работу — __14 баллов__. Сдавать задание после указанного срока сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Весь код должен быть написан самостоятельно. Чужим кодом для пользоваться запрещается даже с указанием ссылки на источник. В разумных рамках, конечно. Взять пару очевидных строчек кода для реализации какого-то небольшого функционала можно.\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "__Мягкий дедлайн 20.12.23__ \\\n",
    "__Жесткий дедлайн 20.12.23__\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит научиться решать задачу Named Entity Recognition (NER) на самом популярном датасете – [CoNLL-2003](https://paperswithcode.com/dataset/conll-2003). В вашем распоряжении будет предобученный BERT, который вам необходимо уменьшить без потерь в качестве. Задание разделено на две части. Первая часть состоит из набора методов по уменьшению модели, которые нужно реализовать по инструкции. Вторая часть – это творческое соревнование, в котором вы можете пользоваться любыми методами, кроме ансамблирования и использования дополнительных данных. Дополнительное условие соревнования: размер вашей модели __не может превышать 20M параметров__.\n",
    "\n",
    "__!!ВАЖНО!!__ Вам придется проводить довольно много экспериментов, поэтому мы рекомендуем не писать весь код в тетрадке, а завести разные файлы для отдельных логических блоков и скомпоновать все в виде проекта. Это позволит вашему ноутбуку не разрастаться и сильно облегчит задачу и вам, и проверяющим.\n",
    "\n",
    "\n",
    "### О датасете\n",
    "\n",
    "В CoNLL-2003 для именования сущностей используется маркировка **BIO** (Beggining, Inside, Outside), в которой метки означают следующее:\n",
    "\n",
    "- *B-{метка}* – начало сущности *{метка}*\n",
    "- *I-{метка}* – продолжнение сущности *{метка}*\n",
    "- *O* – не сущность\n",
    "\n",
    "Существуют так же и другие способы маркировки, например, BILUO. Почитать о них можно [тут](https://en.wikipedia.org/wiki/Inside–outside–beginning_(tagging)) и [тут](https://www.youtube.com/watch?v=dQw4w9WgXcQ).\n",
    "\n",
    "Всего в датасете есть 9 разных меток.\n",
    "- O – слову не соответствует ни одна сущность.\n",
    "- B-PER/I-PER – слово или набор слов соответстует определенному _человеку_.\n",
    "- B-ORG/I-ORG – слово или набор слов соответстует определенной _организации_.\n",
    "- B-LOC/I-LOC – слово или набор слов соответстует определенной _локации_.\n",
    "- B-MISC/I-MISC – слово или набор слов соответстует сущности, которая не относится ни к одной из предыдущих. Например, национальность, произведение искусства, мероприятие и т.д.\n",
    "\n",
    "Приступим!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4877a97d",
   "metadata": {
    "cellId": "0xq7fxh650wapbn36t54y5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Defaulting to user installation because normal site-packages is not writeable',\n",
       " 'Requirement already satisfied: transformers in /home/jupyter/.local/lib/python3.10/site-packages (4.36.2)',\n",
       " 'Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)',\n",
       " 'Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.19.4)',\n",
       " 'Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)',\n",
       " 'Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.10/site-packages (from transformers) (23.2)',\n",
       " 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)',\n",
       " 'Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)',\n",
       " 'Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)',\n",
       " 'Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.15.0)',\n",
       " 'Requirement already satisfied: safetensors>=0.3.1 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.4.1)',\n",
       " 'Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)',\n",
       " 'Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)',\n",
       " 'Requirement already satisfied: typing-extensions>=3.7.4.3 in /kernel/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)',\n",
       " 'Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.10/site-packages (from requests->transformers) (1.25.11)',\n",
       " 'Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)',\n",
       " 'Collecting charset-normalizer~=2.0.0 (from requests->transformers)',\n",
       " '  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)',\n",
       " 'Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.10/site-packages (from requests->transformers) (3.6)',\n",
       " 'Installing collected packages: charset-normalizer',\n",
       " \"  WARNING: The script normalizer is installed in '/home/jupyter/.local/bin' which is not on PATH.\",\n",
       " '  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.',\n",
       " 'Successfully installed charset-normalizer-2.0.12',\n",
       " '',\n",
       " '[notice] A new release of pip is available: 23.2.1 -> 23.3.2',\n",
       " '[notice] To update, run: python3 -m pip install --upgrade pip']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "!!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5cdeed06",
   "metadata": {
    "cellId": "knnqj5fl66jwvf2xum48wj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "59aaeed6",
   "metadata": {
    "cellId": "ml3xpstv6jv8gjrtm24y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 11:51:02.556543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict, List\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032fedc",
   "metadata": {
    "cellId": "ulieua2dzxeou2qn0qvt8c",
    "execution_id": "f9cab768-b185-40b1-94b2-5217f5fc096b"
   },
   "source": [
    "__Задание 1 (0.5 балла)__ Допишите функцию `read_conll2003` для чтения датасета. Внутри она должна проитерироваться по всем строкам файла и для каждого примера составить словарь с полями `words` и `tags` (слова и тэги текста соответственно). На выход функция возвращает список полученных словарей. Тексты в файле разделяются переносом строки `\\n`, а слова и тэги – проблелом. Пример:\n",
    "```\n",
    "! head -n 15 CoNLL2003/train.txt\n",
    "\n",
    "EU B-ORG\n",
    "rejects O\n",
    "German B-MISC\n",
    "call O\n",
    "to O\n",
    "boycott O\n",
    "British B-MISC\n",
    "lamb O\n",
    ". O\n",
    "\n",
    "Peter B-PER\n",
    "Blackburn I-PER\n",
    "\n",
    "BRUSSELS B-LOC\n",
    "1996-08-22 O\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d938b3d3",
   "metadata": {
    "cellId": "qb72wpbmx8q6t53z77ewyf"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def read_conll2003(path: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Read data in CoNNL like format.\n",
    "    \"\"\"\n",
    "\n",
    "    cur_text = {\"words\": [], \"tags\": []}\n",
    "    dataset = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if (line == '\\n'):\n",
    "                dataset.append(cur_text)\n",
    "                cur_text = {\"words\": [], \"tags\": []}\n",
    "            else:\n",
    "                word, tag = line.replace('\\n', '').split(' ')\n",
    "                cur_text[\"words\"].append(word)\n",
    "                cur_text[\"tags\"].append(tag)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0da0a",
   "metadata": {
    "cellId": "5kngflbzgq666aye8ltex6",
    "execution_id": "457a99fc-3636-4db7-91bb-bcf2cc881729"
   },
   "source": [
    "Прочитаем тренировочный и валидационный датасеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "160d6da8",
   "metadata": {
    "cellId": "y4mlbhf2ut1lyw3kvf8pd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_dataset = read_conll2003(\"CoNLL2003/train.txt\")\n",
    "valid_dataset = read_conll2003(\"CoNLL2003/valid.txt\")\n",
    "\n",
    "tags = ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5833f2fd",
   "metadata": {
    "cellId": "surwo11h96mwdfpra5cz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU\tB-ORG\n",
      "rejects\tO\n",
      "German\tB-MISC\n",
      "call\tO\n",
      "to\tO\n",
      "boycott\tO\n",
      "British\tB-MISC\n",
      "lamb\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "sample = train_dataset[0]\n",
    "\n",
    "assert sample['words'] == ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
    "assert sample['tags'] == ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
    "\n",
    "for w, t in zip(sample['words'], sample['tags']):\n",
    "    print(f'{w}\\t{t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c5147",
   "metadata": {
    "cellId": "7jbkgvl7reg727utkfuq",
    "execution_id": "65995df3-ed4f-472b-bde9-29bab831e867"
   },
   "source": [
    "На протяжении всего домашнего задания мы будем использовать _cased_ версию BERT, то есть токенизатор будет учитывать регистр слов. Для задачи NER регистр важен, так как имена и названия организаций или предметов искусства часто пишутся с большой буквы, и будет глупо прятать от модели такую информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bb6cb48d",
   "metadata": {
    "cellId": "o64uaa98nvest86k67ar1m"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53a982fd38742a7a8932e12d6f7727c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1e128bbd0b4d9882c53fb9109e6eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11922b5fe9c149359cab0a5ad698a5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4890ffb029bd428cb50663650b50b1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a8415d",
   "metadata": {
    "cellId": "4f81mvpru4a9924r8dtphj",
    "execution_id": "80e1286b-e8b4-4926-b879-f4ddc2fd4b2f"
   },
   "source": [
    "Заметьте, что при токенизации слова могут разделиться на несколько токенов (как слово `lamb` из примера ниже), из-за чего появится несоответствие между числом токенов и тэгов. Это несоответствие нам придется устранить вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "55a3258a",
   "metadata": {
    "cellId": "zv8bcsiin7ww211bsynof"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова:  ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "Токены: ['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "inputs = tokenizer(sample['words'], is_split_into_words=True)\n",
    "print('Слова: ', sample['words'])\n",
    "print('Токены:', inputs.tokens())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b66a08",
   "metadata": {
    "cellId": "qqej3rpr1qch56ql7j7dc",
    "execution_id": "8c26286a-5611-4af7-9471-ce93280e22e5"
   },
   "source": [
    "К счастью, из выхода токенизатора можно достать список с номерами слов, к которым относится каждый токен. Если номер встретился несколько раз подряд, то слово разделилось. Специальные символы не принадлежат никакому слову, поэтому их номер – `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9ee133b5",
   "metadata": {
    "cellId": "dwhsw25oz66hpwvb4iywfk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44dffd0",
   "metadata": {
    "cellId": "teuoijuu1kswognivpccjg",
    "execution_id": "7a410a8b-7ccd-46d4-8385-390408a16a3e"
   },
   "source": [
    "__Задание 2 (0.5 балла)__ Допишите метод `get_inputs_and_aligned_labels` класса `Dataset`. Он принимает в себя объект из прочитанного выше датасета, токенизирует слова и выравнивает тэги. Выравнивание происходит следующим образом: если токен пренадлежит тому же слову, что и предыдущий токен, и его тэг начинается на `B`, то надо поменять `B` на `I`, потому что это уже продолжение сущности; в любом другом случае тэг токена остается таким же, какой был у соответствующего ему слова.\n",
    "\n",
    "Метод позвращает словарь с полями `input_ids` – результат токенизации, `labels` – индексы тэгов для каждого токена из маппинга `tag2id`, для специальных символов в качестве лейбла укажите -100, так как это значение по умолчанию, которое игнорируется при подсчете кросс-энтропии в классе `CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "45a724ca",
   "metadata": {
    "cellId": "md29ww2nppsh3nh4lpiib"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class Dataset:\n",
    "    def __init__(self, raw_dataset: List[Dict[str, str]], tag2id: Dict[str, int]):\n",
    "        \"\"\"\n",
    "        :params:\n",
    "        raw_dataset: output of read_conll2003 function\n",
    "        tag2id: mapping from tag name to its id\n",
    "        \"\"\"\n",
    "        self.dataset = raw_dataset\n",
    "        self.tag2id = tag2id\n",
    "\n",
    "    def _find_next(self, token, words, i, j):\n",
    "        for c_i in range(i, len(words)):\n",
    "            while (j < len(words[c_i])):\n",
    "                if words[c_i][j:].startswith(token):\n",
    "                    i = c_i\n",
    "                    return i, j\n",
    "                j += 1\n",
    "            j = 0\n",
    "        return i, j\n",
    "\n",
    "    def get_inputs_and_aligned_labels(self, sample):\n",
    "        \"\"\"\n",
    "        Aligns tags with tokens and returns dict with token ids and tag ids.\n",
    "        \"\"\"\n",
    "        tokenized = tokenizer(sample['words'], is_split_into_words=True)\n",
    "        tags = sample['tags']\n",
    "\n",
    "        special_tokens = ['[CLS]', '[SEP]', '[PAD]']\n",
    "        labels = []\n",
    "        i = -1\n",
    "        j = 0\n",
    "        for token in tokenized['input_ids']:\n",
    "            source_token = tokenizer.convert_ids_to_tokens(token)\n",
    "            if source_token in special_tokens:\n",
    "                labels.append(-100)\n",
    "            else:\n",
    "                if source_token.startswith('##'):\n",
    "                    source_token = source_token[2:]\n",
    "                    i, j = self._find_next(source_token, sample['words'], i, j)\n",
    "                    new_tag = 'I' + tags[i][1:] if tags[i].startswith('B') else tags[i]\n",
    "                    labels.append(self.tag2id[new_tag])\n",
    "                else:\n",
    "                    i, j = self._find_next(source_token, sample['words'], i, j)\n",
    "                    labels.append(self.tag2id[tags[i]])\n",
    "\n",
    "        assert len(tokenized['input_ids']) == len(labels), \"ids and labels must be the same length\"\n",
    "\n",
    "        return {\n",
    "            'input_ids': tokenized['input_ids'],\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        return self.get_inputs_and_aligned_labels(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9ce3abc9",
   "metadata": {
    "cellId": "4l5hd1sbuck9gfgfoq6apm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tag2id = {tag: i for i, tag in enumerate(tags)}\n",
    "id2tag = {i: tag for tag, i in tag2id.items()}\n",
    "\n",
    "train_dataset = Dataset(train_dataset, tag2id)\n",
    "valid_dataset = Dataset(valid_dataset, tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "23d7c9a3",
   "metadata": {
    "cellId": "riwgyd74wklydb4m44hme"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 2, 8, 1, 8, 8, 8, 1, 8, 8, 8, -100]\n",
      "101\t[CLS]\t-100\t\n",
      "7270\tEU\t2\tB-ORG\n",
      "22961\trejects\t8\tO\n",
      "1528\tGerman\t1\tB-MISC\n",
      "1840\tcall\t8\tO\n",
      "1106\tto\t8\tO\n",
      "21423\tboycott\t8\tO\n",
      "1418\tBritish\t1\tB-MISC\n",
      "2495\tla\t8\tO\n",
      "12913\t##mb\t8\tO\n",
      "119\t.\t8\tO\n",
      "102\t[SEP]\t-100\t\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "sample = train_dataset[0]\n",
    "\n",
    "input_ids, labels = sample['input_ids'], sample['labels']\n",
    "print(labels)\n",
    "assert input_ids == [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102]\n",
    "assert labels == [-100, 2, 8, 1, 8, 8, 8, 1, 8, 8, 8, -100]\n",
    "\n",
    "for idx, token, label in zip(input_ids, tokenizer.convert_ids_to_tokens(input_ids), labels):\n",
    "    tag = id2tag[label] if label != -100 else ''\n",
    "    print(f'{idx}\\t{token}\\t{label}\\t{tag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af09d9",
   "metadata": {
    "cellId": "dot4ccqvatck076uils2us",
    "execution_id": "756cb3bc-09d9-4f7c-b84b-d021c2f1b960"
   },
   "source": [
    "На данный момент наш датасет возвращает по индексу списки токенов и меток, но при формировании батча нам надо их дополнить паддингами. Для этого существует Collator – класс, который вызывается при формировании батча. Он принимает набор произвольных объектов из датасета и делает из них тензоры согласно инструкциям. Для задачи классификации последовательности имеется специальный `DataCollatorForTokenClassification`, который добавляет паддинги к токенам и меткам, что нам собственно и нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a1c1d91c",
   "metadata": {
    "cellId": "ol3xn2go67h3kh2ar17x"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fd89b2a8",
   "metadata": {
    "cellId": "23qmoil2vaax5go1hhddzb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поля:\n",
      " dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "\n",
      "Индексы токенов:\n",
      " tensor([[  101,  7270, 22961,  1528,  1840,  1106, 21423,  1418,  2495, 12913,\n",
      "           119,   102],\n",
      "        [  101,  1943, 14428,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n",
      "\n",
      "Индексы меток:\n",
      " tensor([[-100,    2,    8,    1,    8,    8,    8,    1,    8,    8,    8, -100],\n",
      "        [-100,    3,    7, -100, -100, -100, -100, -100, -100, -100, -100, -100]])\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "batch = data_collator([train_dataset[i] for i in range(2)])\n",
    "print('Поля:\\n', batch.keys())\n",
    "print('\\nИндексы токенов:\\n', batch['input_ids'])\n",
    "print('\\nИндексы меток:\\n', batch['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ca989",
   "metadata": {
    "cellId": "7ozi1l71b1jrsjiexjitd",
    "execution_id": "4251b4ef-339f-46f1-bdd4-d9f7184df757"
   },
   "source": [
    "Теперь мы готовы обернуть всю нашу красоту в `DataLoader`, по которому будем итерироваться при обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8c268c53",
   "metadata": {
    "cellId": "rqc573rjn36qs55sm6tfq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f31b9",
   "metadata": {
    "cellId": "69gkilj3527b5mpxnwplp4",
    "execution_id": "ff6d4150-868a-4674-bcd2-123d40b138e4"
   },
   "source": [
    "### Метрика\n",
    "\n",
    "Для оценки качества NER чаще всего используется F1-мера. Разделяют два метода подсчета метрики:\n",
    "1) Token-level: считается правильность предсказания отденьной метки для каждого токена.\n",
    "2) Entity-level: считается правильность предсказания метки для всей сущности целиком независимо от того, сколько слов или токенов в нее входит.\n",
    "\n",
    "Обычно предпочтение отдается второму способу, так как иначе, во-первых, качество зависит от токенизации, а во-вторых, если сущность состоит из нескольких слов и модель выставляет словам разные метки, то становится непонятно, к какому именно классу относить данную сущность. Для практики такой результат настолько же плох, насколько полное неугадывание класса, поэтому странно давать за это баллы.\n",
    "\n",
    "Заметьте, предсказание `[I-PER', 'I-PER]` при верном `[B-PER', 'I-PER]` считается корректным, так как из него можно однозначно восстановить ответ, догадавшись, что не первом месте должно стоять `B-`. В то же время при верном `[B-PER', 'B-PER]` такое предсказание корректным не будет.\n",
    "\n",
    "Для подсчета метрики будем использовать уже готовое [решение](https://huggingface.co/spaces/evaluate-metric/seqeval) из библиотеки `seqeval` (семейство `huggingface`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e2dd333e",
   "metadata": {
    "cellId": "5urgjasi910sxus3mnvca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Defaulting to user installation because normal site-packages is not writeable',\n",
       " 'Requirement already satisfied: transformers[torch] in /home/jupyter/.local/lib/python3.10/site-packages (4.36.2)',\n",
       " 'Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)',\n",
       " 'Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers[torch]) (0.19.4)',\n",
       " 'Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.22.4)',\n",
       " 'Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.10/site-packages (from transformers[torch]) (23.2)',\n",
       " 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)',\n",
       " 'Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)',\n",
       " 'Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.27.1)',\n",
       " 'Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers[torch]) (0.15.0)',\n",
       " 'Requirement already satisfied: safetensors>=0.3.1 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers[torch]) (0.4.1)',\n",
       " 'Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.65.0)',\n",
       " 'Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)',\n",
       " 'Requirement already satisfied: accelerate>=0.21.0 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers[torch]) (0.25.0)',\n",
       " 'Requirement already satisfied: psutil in /kernel/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.7.3)',\n",
       " 'Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)',\n",
       " 'Requirement already satisfied: typing-extensions>=3.7.4.3 in /kernel/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.8.0)',\n",
       " 'Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.11.1)',\n",
       " 'Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)',\n",
       " 'Requirement already satisfied: jinja2 in /kernel/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)',\n",
       " 'Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.0.0)',\n",
       " 'Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (3.25.2)',\n",
       " 'Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (16.0.6)',\n",
       " 'Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.10/site-packages (from requests->transformers[torch]) (1.25.11)',\n",
       " 'Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)',\n",
       " 'Collecting charset-normalizer~=2.0.0 (from requests->transformers[torch])',\n",
       " '  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)',\n",
       " 'Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)',\n",
       " 'Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)',\n",
       " 'Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)',\n",
       " 'Installing collected packages: charset-normalizer',\n",
       " \"  WARNING: The script normalizer is installed in '/home/jupyter/.local/bin' which is not on PATH.\",\n",
       " '  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.',\n",
       " 'Successfully installed charset-normalizer-2.0.12',\n",
       " '',\n",
       " '[notice] A new release of pip is available: 23.2.1 -> 23.3.2',\n",
       " '[notice] To update, run: python3 -m pip install --upgrade pip']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "!!pip install seqeval\n",
    "!!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8832edf3",
   "metadata": {
    "cellId": "nheh21hkfgbf0gxs0zsspa"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from seqeval.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "054e6846",
   "metadata": {
    "cellId": "uhj6iekikzamvajfypr6yo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5714285714285714, 0.4)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# here are 7 labels in total, we guessed correctly 4 of them.\n",
    "\n",
    "predictions = [['O', 'I-PER', 'I-PER', 'O'], ['I-PER', 'I-PER', 'O']]\n",
    "references = [['O', 'B-PER', 'B-PER', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "acc = accuracy_score(predictions, references)\n",
    "f1 = f1_score(references, predictions)\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9f44778c",
   "metadata": {
    "cellId": "b5f7t8y1xvmcu2ukrp5rn9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def calc_f1(predictions: List[List[int]], labels: List[List[int]]):\n",
    "    \"\"\"\n",
    "    :params:\n",
    "    predictions: list of lists of predicted labels\n",
    "    labels: list of lists of ground truth labels\n",
    "    \"\"\"\n",
    "    text_labels = [[id2tag[l] for l in label if l != -100] for label in labels]\n",
    "    text_predictions = []\n",
    "    for i in range(len(text_labels)):\n",
    "        # +1 because we skip the first ([CLS]) token\n",
    "        sample_text_preds = [id2tag[predictions[i][j + 1]] for j in range(len(text_labels[i]))]\n",
    "        text_predictions.append(sample_text_preds)\n",
    "\n",
    "    return f1_score(text_labels, text_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b9140",
   "metadata": {
    "cellId": "ut8bctni13j8v66s5ays",
    "execution_id": "46382815-b94e-44bb-9f73-8156f9dda8b4"
   },
   "source": [
    "### Модель\n",
    "\n",
    "В качестве начальной модели мы будем использовать предобученный BERT, а если быть точнее `bert-base-cased` из библиотеки `huggingface`. Он содержит 107М параметров. В последующих заданиях мы будем реализовывать методы для уменьшения его размеров с минимальной потерей качества.\n",
    "\n",
    "Для классификации последовательностей в `transformers` существует специальная обертка `AutoModelForTokenClassification`. Воспользуемся ею и обернем нашу модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c302fcdf",
   "metadata": {
    "cellId": "yn5f4hphwqmp62gbnj1n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 107726601\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model = AutoModelForTokenClassification.from_pretrained('bert-base-cased', id2label=id2tag, label2id=tag2id).to(device)\n",
    "print('Number of parameters:', sum([p.numel() for p in model.parameters()]))\n",
    "teacher_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69168af1",
   "metadata": {
    "cellId": "xn0lirdlw4e674h82eea28",
    "execution_id": "75cdff0f-0029-4e06-9904-60e8f04b5f77"
   },
   "source": [
    "## Обучение всякого"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a019c",
   "metadata": {
    "cellId": "4h3pgm0d9l3c212wwn92kw",
    "execution_id": "1246dd6a-3f40-4627-a4b7-ac1998cfc6ad"
   },
   "source": [
    "**Задание 3 (1 балл)** Все методы уменьшения размерности основываются на том, что у нас есть некоторая обученная модель. Сейчас у нас есть предобученный BERT, но на задачу MLM, а не NER. Дообучите BERT на нашем датасете. Ориентировочно у вас должно получиться значение F1 не меньше 0.93 на валидационной выборке. Само обучение никак не должно занимать больше получаса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f0dfb623",
   "metadata": {
    "cellId": "txuw257n44acx5nziddc8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"f1 score\": calc_f1(predictions, labels)\n",
    "    }\n",
    "\n",
    "def train_bert(model, data_collator, train_dataset, valid_dataset, args_dir=\"training_args\", epochs=3.0):\n",
    "    args = TrainingArguments(args_dir,\n",
    "                        evaluation_strategy=\"epoch\",\n",
    "                        save_strategy=\"no\",\n",
    "                        num_train_epochs=epochs\n",
    "                        )\n",
    "\n",
    "    trainer = Trainer(model,\n",
    "                      args=args,\n",
    "                      data_collator=data_collator,\n",
    "                      train_dataset=train_dataset,\n",
    "                      eval_dataset=valid_dataset,\n",
    "                      compute_metrics=compute_metrics)\n",
    "    trainer.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "060b924f",
   "metadata": {
    "cellId": "szl87js57va4v5hhims8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5622' max='5622' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5622/5622 06:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.087247</td>\n",
       "      <td>0.909037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.078610</td>\n",
       "      <td>0.922407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.064889</td>\n",
       "      <td>0.935960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "teacher_model = train_bert(model, data_collator, train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab6aa6",
   "metadata": {
    "cellId": "uvfhgpqhwxdtjwrsq5ugrf",
    "execution_id": "39c549ab-d2e9-44f9-bbb0-537b503344cd"
   },
   "source": [
    "### Embedding factorization\n",
    "\n",
    "Можно заметить, что на данный момент матрица эмбеддингов занимает $V \\cdot H = 28996 \\cdot 768 = 22.268.928$ параметров. Это целая пятая часть от всей модели! Давайте попробуем с этим что-то сделать. В вариации [ALBERT](https://arxiv.org/pdf/1909.11942.pdf) предлагается факторизовать матрицу эмбеддингов в произведение двух небольших матриц. Таким образом, параметры эмбеддингов будут содержать $V \\cdot E + E \\cdot H$ элементов, что гораздо меньше, если $H \\gg E$. Авторы выбирают $E = 128$, однако ничего не мешает вам взять значение меньше.\n",
    "\n",
    "__Задание 4 (1 балл)__ Замените слой эмбеддингов на описанную факторизацию и дообучите полученную в предыдущем задании модель. Насколько вам удалось уменьшить число параметров? Если вы все сделали правильно, то F1-мера на валидации не должна опуститься ниже 0.9.\n",
    "\n",
    "Мы настоятельно рекомендуем переиспользовать код для обучения из предыдущего задания и не создавать новую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47aa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): EmbedFactorized(\n",
       "        (emb1): Embedding(28996, 128, padding_idx=0)\n",
       "        (emb2): Embedding(128, 768, padding_idx=0)\n",
       "      )\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "from module import EmbedFactorized\n",
    "model.bert.embeddings.word_embeddings = EmbedFactorized(28996, 768, E=128, padding_idx=0, embedding_matrix=model.bert.embeddings.word_embeddings.weight.data)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f2677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 89267465\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print('Number of parameters:', sum([p.numel() for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03394e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9370' max='9370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9370/9370 09:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.214531</td>\n",
       "      <td>0.781443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.150203</td>\n",
       "      <td>0.853233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.854876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.165267</td>\n",
       "      <td>0.869291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.169136</td>\n",
       "      <td>0.882552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_bert(model, data_collator, train_dataset, valid_dataset, \"embedding_factorization\", epochs=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84079e19",
   "metadata": {
    "cellId": "ox2r27l6ote12gm19b8e2jc",
    "execution_id": "f47a96b7-c14c-4fe1-86fc-9c09a0c18b5f"
   },
   "source": [
    "### Дистилляция знаний\n",
    "\n",
    "Дистилляция знаний – это парадигма обучения, в которой знания модели-учителя дистиллируются в модель-ученика. Учеником может быть произвольная модель меньшего размера, решающая ту же задачу. При дистилляции используются два функционала ошибки:\n",
    "\n",
    "1. Стандартная кросс-энтропия.\n",
    "1. Функция, задающая расстояние между распределениями предсказаний учителя и ученика. Чаще всего используют кросс-энтропию или KL-дивергенцию.\n",
    "\n",
    "При этом для того, чтобы распределение предсказаний учителя не было таким вырожденным используют softmax с температурой больше 1, например, 2 или 5.\n",
    "\n",
    "<img src=\"https://intellabs.github.io/distiller/imgs/knowledge_distillation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f5440f",
   "metadata": {
    "cellId": "je94i895rpqfakar2i3il",
    "execution_id": "c416911d-4f93-4d56-b40f-915bb00d57e1"
   },
   "source": [
    "__Задание 5 (1 балл)__ Реализуйте метод дистилляции знаний, изображенный на картинке. Для подсчета ошибки между предсказаниями ученика и учителя используйте KL-дивергенцию (`nn.KLDivLoss(reduction=\"batchmean\")`). В качестве учителя используйте дообученный BERT из задания 3. В качестве ученика вы можете взять произвольную необученную модель с размером около 40M параметров. Не забудьте про warmup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6d6abb59",
   "metadata": {
    "cellId": "4i4nqr87efshelik3wa7hj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from trainer import DistilTrainer\n",
    "\n",
    "def train_distil(student_model, teacher_model, data_collator, train_dataset, valid_dataset, args_dir=\"training_args\", epochs=3.0):\n",
    "    args = TrainingArguments(args_dir,\n",
    "                        evaluation_strategy=\"epoch\",\n",
    "                        save_strategy=\"no\",\n",
    "                        num_train_epochs=epochs,\n",
    "                        warmup_ratio=0.06,\n",
    "                        weight_decay=1e-5,\n",
    "                        lr_scheduler_type=\"linear\"\n",
    "                        )\n",
    "\n",
    "    trainer = DistilTrainer(student_model,\n",
    "                      teacher_model=teacher_model,\n",
    "                      temperature=2.0,\n",
    "                      lambda_param=0.5,\n",
    "                      args=args,\n",
    "                      data_collator=data_collator,\n",
    "                      train_dataset=train_dataset,\n",
    "                      eval_dataset=valid_dataset,\n",
    "                      compute_metrics=compute_metrics)\n",
    "    trainer.train()\n",
    "    return student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d682c123",
   "metadata": {
    "cellId": "o6bq7hyyi4oszz830k7on"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of student parameters: 29655177\n",
      "Number of teacher parameters: 107726601\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187400' max='187400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187400/187400 2:46:30, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54.093000</td>\n",
       "      <td>39.320770</td>\n",
       "      <td>0.124388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>36.174500</td>\n",
       "      <td>27.779524</td>\n",
       "      <td>0.351824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24.214500</td>\n",
       "      <td>20.988920</td>\n",
       "      <td>0.472730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19.279900</td>\n",
       "      <td>18.165960</td>\n",
       "      <td>0.543808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>15.475200</td>\n",
       "      <td>16.031973</td>\n",
       "      <td>0.583740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>13.127300</td>\n",
       "      <td>15.051217</td>\n",
       "      <td>0.607172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>11.038200</td>\n",
       "      <td>13.887386</td>\n",
       "      <td>0.669031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.546200</td>\n",
       "      <td>13.180466</td>\n",
       "      <td>0.680142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7.977600</td>\n",
       "      <td>12.670936</td>\n",
       "      <td>0.703784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.052700</td>\n",
       "      <td>12.587157</td>\n",
       "      <td>0.706190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.826800</td>\n",
       "      <td>11.787175</td>\n",
       "      <td>0.732131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.649800</td>\n",
       "      <td>12.087781</td>\n",
       "      <td>0.733305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.427300</td>\n",
       "      <td>11.550864</td>\n",
       "      <td>0.738556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.660900</td>\n",
       "      <td>11.541844</td>\n",
       "      <td>0.740841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.201000</td>\n",
       "      <td>11.508191</td>\n",
       "      <td>0.738039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.037700</td>\n",
       "      <td>11.318020</td>\n",
       "      <td>0.742429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.614000</td>\n",
       "      <td>11.701701</td>\n",
       "      <td>0.744831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.486600</td>\n",
       "      <td>11.133085</td>\n",
       "      <td>0.745154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.622600</td>\n",
       "      <td>11.212312</td>\n",
       "      <td>0.747072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.055200</td>\n",
       "      <td>11.212063</td>\n",
       "      <td>0.760017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.949100</td>\n",
       "      <td>10.995238</td>\n",
       "      <td>0.760725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.011000</td>\n",
       "      <td>10.993455</td>\n",
       "      <td>0.764105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.627900</td>\n",
       "      <td>11.044083</td>\n",
       "      <td>0.765566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.528100</td>\n",
       "      <td>11.099371</td>\n",
       "      <td>0.770674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.380900</td>\n",
       "      <td>10.652413</td>\n",
       "      <td>0.764218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.398300</td>\n",
       "      <td>10.211901</td>\n",
       "      <td>0.767570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.211700</td>\n",
       "      <td>10.979979</td>\n",
       "      <td>0.767551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.024500</td>\n",
       "      <td>10.553851</td>\n",
       "      <td>0.771712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.049200</td>\n",
       "      <td>10.314637</td>\n",
       "      <td>0.768444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.058100</td>\n",
       "      <td>10.924290</td>\n",
       "      <td>0.776272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.935000</td>\n",
       "      <td>10.324912</td>\n",
       "      <td>0.770934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.056500</td>\n",
       "      <td>11.286303</td>\n",
       "      <td>0.768881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.813700</td>\n",
       "      <td>10.433493</td>\n",
       "      <td>0.767685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.875400</td>\n",
       "      <td>10.302073</td>\n",
       "      <td>0.772793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.713800</td>\n",
       "      <td>10.972658</td>\n",
       "      <td>0.766168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.583400</td>\n",
       "      <td>10.913469</td>\n",
       "      <td>0.764438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.534900</td>\n",
       "      <td>10.616923</td>\n",
       "      <td>0.772704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.511800</td>\n",
       "      <td>10.455477</td>\n",
       "      <td>0.768558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.592900</td>\n",
       "      <td>10.544552</td>\n",
       "      <td>0.767310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.544200</td>\n",
       "      <td>10.494296</td>\n",
       "      <td>0.773465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.406700</td>\n",
       "      <td>10.266421</td>\n",
       "      <td>0.775735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.333500</td>\n",
       "      <td>10.297452</td>\n",
       "      <td>0.768818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.359600</td>\n",
       "      <td>10.280462</td>\n",
       "      <td>0.776111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.323200</td>\n",
       "      <td>10.407057</td>\n",
       "      <td>0.776984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.262400</td>\n",
       "      <td>10.506085</td>\n",
       "      <td>0.770312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.281600</td>\n",
       "      <td>10.257813</td>\n",
       "      <td>0.774283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.271000</td>\n",
       "      <td>10.189353</td>\n",
       "      <td>0.778926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.257200</td>\n",
       "      <td>10.434667</td>\n",
       "      <td>0.777520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.202400</td>\n",
       "      <td>10.318051</td>\n",
       "      <td>0.771528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.092300</td>\n",
       "      <td>10.193088</td>\n",
       "      <td>0.779912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.174600</td>\n",
       "      <td>10.191698</td>\n",
       "      <td>0.777255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.056200</td>\n",
       "      <td>10.010435</td>\n",
       "      <td>0.777479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.045400</td>\n",
       "      <td>10.257730</td>\n",
       "      <td>0.775543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.095400</td>\n",
       "      <td>10.291419</td>\n",
       "      <td>0.774222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.146200</td>\n",
       "      <td>10.072107</td>\n",
       "      <td>0.778992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.990600</td>\n",
       "      <td>10.259156</td>\n",
       "      <td>0.777923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.944200</td>\n",
       "      <td>9.789970</td>\n",
       "      <td>0.778822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.970100</td>\n",
       "      <td>10.106958</td>\n",
       "      <td>0.781359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.977400</td>\n",
       "      <td>10.425708</td>\n",
       "      <td>0.777220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.922900</td>\n",
       "      <td>10.310647</td>\n",
       "      <td>0.778597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.928100</td>\n",
       "      <td>10.108337</td>\n",
       "      <td>0.779869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.888100</td>\n",
       "      <td>10.094374</td>\n",
       "      <td>0.780742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.900300</td>\n",
       "      <td>10.224483</td>\n",
       "      <td>0.786924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.919400</td>\n",
       "      <td>10.325427</td>\n",
       "      <td>0.778259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>10.224474</td>\n",
       "      <td>0.780085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.834300</td>\n",
       "      <td>10.122982</td>\n",
       "      <td>0.784709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.877300</td>\n",
       "      <td>10.046647</td>\n",
       "      <td>0.784762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.874800</td>\n",
       "      <td>9.874021</td>\n",
       "      <td>0.781329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.749400</td>\n",
       "      <td>9.822492</td>\n",
       "      <td>0.786632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>10.244246</td>\n",
       "      <td>0.785396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.772100</td>\n",
       "      <td>10.051801</td>\n",
       "      <td>0.780098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.787400</td>\n",
       "      <td>10.266832</td>\n",
       "      <td>0.782074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>10.070870</td>\n",
       "      <td>0.778020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.701200</td>\n",
       "      <td>10.229710</td>\n",
       "      <td>0.783302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.720400</td>\n",
       "      <td>9.802088</td>\n",
       "      <td>0.784651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.781800</td>\n",
       "      <td>10.032188</td>\n",
       "      <td>0.782888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.712600</td>\n",
       "      <td>9.902110</td>\n",
       "      <td>0.783930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.763500</td>\n",
       "      <td>10.024257</td>\n",
       "      <td>0.783912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.657400</td>\n",
       "      <td>10.087715</td>\n",
       "      <td>0.779409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.707400</td>\n",
       "      <td>10.067975</td>\n",
       "      <td>0.784423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>9.973853</td>\n",
       "      <td>0.781013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.616800</td>\n",
       "      <td>10.002260</td>\n",
       "      <td>0.781081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.619700</td>\n",
       "      <td>9.995139</td>\n",
       "      <td>0.787088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.692600</td>\n",
       "      <td>9.996823</td>\n",
       "      <td>0.787105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.627400</td>\n",
       "      <td>9.936013</td>\n",
       "      <td>0.781862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>9.937101</td>\n",
       "      <td>0.783073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>10.016731</td>\n",
       "      <td>0.783003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.567800</td>\n",
       "      <td>9.873406</td>\n",
       "      <td>0.784463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.551600</td>\n",
       "      <td>9.998450</td>\n",
       "      <td>0.780904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.611600</td>\n",
       "      <td>9.922817</td>\n",
       "      <td>0.781517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.566400</td>\n",
       "      <td>9.966940</td>\n",
       "      <td>0.785337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.584300</td>\n",
       "      <td>9.927287</td>\n",
       "      <td>0.783523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>9.892607</td>\n",
       "      <td>0.782736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.601500</td>\n",
       "      <td>9.858597</td>\n",
       "      <td>0.784886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>9.903718</td>\n",
       "      <td>0.785286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.540800</td>\n",
       "      <td>9.904010</td>\n",
       "      <td>0.783950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.605800</td>\n",
       "      <td>9.819032</td>\n",
       "      <td>0.785782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.540400</td>\n",
       "      <td>9.865961</td>\n",
       "      <td>0.786336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>9.838868</td>\n",
       "      <td>0.786430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>9.844454</td>\n",
       "      <td>0.784973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "from transformers import DistilBertForTokenClassification, DistilBertConfig\n",
    "\n",
    "configuration = DistilBertConfig(dim=384, num_labels=9)\n",
    "student_model = DistilBertForTokenClassification(configuration).to(device)\n",
    "print('Number of student parameters:', sum([p.numel() for p in student_model.parameters()]))\n",
    "\n",
    "print('Number of teacher parameters:', sum([p.numel() for p in teacher_model.parameters()]))\n",
    "\n",
    "distilled_model = train_distil(student_model, teacher_model, data_collator, train_dataset, valid_dataset, args_dir=\"distil_bert\", epochs=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2b9e4",
   "metadata": {
    "cellId": "k5o3a18barjjrrrbffdd9b",
    "execution_id": "9073d024-a241-4919-93a5-a9722f6e40fc",
    "tags": []
   },
   "source": [
    "## Соревнование (до 10 баллов)\n",
    "\n",
    "Ваша задача – обучить модель с размером __не больше 20М параметров__ для задачи NER. При этом можно пользоваться предобученным `bert-base-cased`, но больше ничем. \n",
    "\n",
    "Соревнование будет проходить аналогично соревнованию из второго домашнего задания. Ваши посылки вы должны будете отправлять тг-боту [@nlp_hw4_bot](t.me/nlp_hw4_bot), а он будет считать значения F1 на публичном и приватном датасетах и записывать результат в [табличку](https://docs.google.com/spreadsheets/d/1rILRI16VxgztwlfqR2kPZ3MxlJkerz6iEr5Kx9yrOLA/edit#gid=0).\n",
    "\n",
    "Для формирования посылки вам нужно будет создать папку на dropbox, положить в нее файл `model.py` с классом модели `Model` и веса `weights.pt`, а затем отправить боту ссылку на эту папку, доступную к чтению. Бот будет импортировать модель и загружать веса:\n",
    "```\n",
    "module = __import__('model', globals(), locals(), ['Model'], 0)\n",
    "model = module.Model()\n",
    "model.load_state_dict(torch.load('weights.pt', map_location=torch.device('cpu')))\n",
    "```\n",
    "\n",
    "При тестировании модель будет получать на вход `input_ids` и `attention_mask`, а на выход должна возвращать трехмерный тензор с вероятностями меток для каждого токена в батче. Класс `Model` должен содержать атрибут `id2label` совпадающий с тем, который задан в конфиге модели `model.config.id2label`. Это нужно для того, чтобы id тэгов мапились в нужные названия тэгов, так как они могут отличаться у разных решений.\n",
    "\n",
    "\n",
    "__Обязательм условием__ участия в соревновании является отчет о проделанной работе в формате pdf, в котором вы должны описать опробованные методы с результатами. За отчет выставляется максимум до __2 баллов__ на усмотрение проверяющего. В случае отсутствия отчета баллы за соревнование __обнуляются__.\n",
    "\n",
    "После дедлайна по домашке будут выложен _приватный_ лидерборд, по которому и будут выставляться баллы за соревнования. За место в лидерборде можно получить до __8__ баллов, но только при условии, если вы получили больше __0.8__ на _публичном_ лидерборде, в противном случае баллы выставляться не будут.\n",
    "$$\n",
    "\\text{число баллов} = 8\\frac{(N - r + 1)}{N},\n",
    "$$\n",
    "где $r$ – место в лидерборде, а $N$ - число участников со значением F1 на _публичном_ лидерборде не меньше __0.8__.\n",
    "\n",
    "\n",
    "На сервере установлена версия библиотеки `transformers==4.34.0`.\n",
    "В разных версиях может отличаться вид хранения весов, поэтому рекомендуем установить себе такую же версию, чтобы избежать ошибок при загрузке модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c3df0",
   "metadata": {
    "cellId": "2dmddbtnseluiy10hosry",
    "execution_id": "4f92ed22-dec2-4ed1-a48f-fdaaa2401cfc"
   },
   "source": [
    "### Что стоит попробовать?\n",
    "\n",
    "* В статье [ALBERT](https://arxiv.org/abs/1909.11942) помимо факторизации эмбеддингов предлагается использовать одни и те же параметры для нескольких слоев. Такой подход позволяет серьезно уменьшить число параметров.\n",
    "\n",
    "* В задании 5 мы инициализировали ученика случайно, однако можно сделать лучше. При дистилляции знаний для downstream задачи из предобученного в unsupervised формате учителя (задача MLM) часто помогает сперва дистиллировать модель для задачи предобучения, а затем ее уже дообучать на downstream задачу с соответствующим учителем. Другими словами, лучше сначала дистиллировать предобученный BERT в ученика на MLM задаче, а затем использовать этого ученика в качестве начальной инициализации для второй дистилляции.\n",
    "\n",
    "* При дистилляции мы выравниваем только предсказания моделей, однако можно выравнивать еще и скрытые слои. Например, приближать матрицы внимания и выходы каждого скрытого слоя. Подробнее об этом можно почитать [тут](https://www.researchgate.net/publication/375758425_Knowledge_Distillation_Scheme_for_Named_Entity_Recognition_Model_Based_on_BERT).\n",
    "\n",
    "* В данный момент мы используем все головы внимания, но ряд исследований показывает, что большинство из них можно выбросить без потери качества. В этой [статье](https://arxiv.org/pdf/1905.09418.pdf) предлагается следующий подход. Добавим гейт $g_i \\in \\{0, 1\\}$ для каждой головы внимания.\\\n",
    "$$\n",
    "\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_I^V)\n",
    "$$\n",
    "$$\n",
    "\\text{MultiHeadAttention}(Q, K, V) = \\text{Concat}(g_i \\cdot \\text{head}_i) W^O\n",
    "$$\n",
    "---\n",
    "__Теоретический блок для тех, кому интересно__   \n",
    "Будем настраивать значения гейтов в процессе обучения. Мы хотим, чтобы как можно большая часть гейтов стала нулями, поэтому добавим в функционал модели $L_0$ регуляризацию на $g_i$. Проблема в том, что $L_0$ – недифференцируемая функция, поэтому нам надо релаксировать ее.\n",
    "Будем считать, что каждый гейт задается распределением Бернулли, $g_i \\sim \\text{Bernoulli}(\\alpha_i)$, где $\\alpha_i$ – настраиваемый параметр. Осталось понять, как его настраивать. Если мы будем напрямую семплировать из распределения Бернулли, то мы потеряем связь между $\\alpha_i$ и семплом, поэтому мы не сможем прокинуть градиенты (такая же проблема возникает в VAE, там используют reparametrization trick). Существует хороший способ семплирования дискретных случайных величин с сохранением связи – __Gumbel-Max trick__. Пусть вероятность каждого значения случайной величины пропорциональна $\\beta_k \\in (0, \\infty)$ и \\\n",
    "$$\n",
    "x = \\text{argmax}_k \\{\\log \\beta_k - \\log(-\\log(\\text{Uniform}(0, 1))) \\},\n",
    "$$\n",
    "Тогда $P(x = k) = \\frac{\\beta_k}{\\sum_k \\beta_k}$. Для того, чтобы избавиться от недифференцируемого аргмакса можно релаксировать его, заменив на softmax с температурой меньше 1, так мы получим [Concrete distribution](https://arxiv.org/pdf/1611.00712.pdf). Теперь мы сможем в процессе обучения семплировать значения гейтов и обновлять $\\alpha_i$ градиентным спуском. Почти победа, осталось понять, при каких значениях $\\alpha_i$ после обучения мы будем считать, что гейт закрыт и голову можно выбросить. В [статье](https://arxiv.org/pdf/1712.01312.pdf) про Hard Concrete распределение, предложившей $L_0$ регуляризацию, предлагается немного растянуть распределение вероятности открытия гейта с $[0, 1]$ до $[\\gamma, \\zeta]$ (например, $[-0.1, 1.1]$), а затем обрезать его обратно до $[0, 1]$. Таким образом, все значения, которые были меньше 0, превратятся в 0. Теперь мы будем считать гейт закрытым, если мы получили на выходе 0.\n",
    "$$g_i = \\text{clip}\\big(\\text{Sigmoid}(\\log \\alpha_i)(\\zeta - \\gamma) + \\gamma, 0, 1\\big)$$\n",
    "---\n",
    "Получаем следующий алгоритм подбора значений для гейтов.\n",
    "1. Заводим параметр $\\log \\alpha_i$ для каждой головы каждого слоя.\n",
    "2. Добавляем к функционалу ошибки слагаемое регуляризации с небольшим коэффициентом $\\lambda$ (например, $0.02$)\n",
    "$$\n",
    "\\mathcal{L}_C = \\sum_{i=1}^h (1 - P(g_i = 1 | \\alpha_i)) = \\sum_{i=1}^h \\text{Sigmoid}\\Big(\\log \\alpha_i - \\tau \\log \\frac{-\\gamma}{\\zeta}\\Big),\n",
    "$$\n",
    "где $\\gamma$ < 0 и $\\zeta$ > 1, $\\tau$ – гиперпараметры (можно взять $-0.1$, $1.1$ и $0.33$ соответственно)\n",
    "3. При каждом вызове модели значения гейтов семплируются из Hard Concrete распределения.\n",
    "\\begin{align}\n",
    "u &= \\text{Uniform}(0, 1) \\\\\n",
    "z &= \\text{Sigmoid}\\big((\\log u - \\log(1 - u) + \\log \\alpha_i) \\,/\\, \\tau\\big) \\\\\n",
    "g_i &= \\text{clip}\\big( z (\\zeta - \\gamma) + \\gamma, 0, 1 \\big)\n",
    "\\end{align}\n",
    "4. После обучения в идеале выбрасываются головы, для которых $\\text{clip}\\big(\\text{Sigmoid}(\\log \\alpha_i)(\\zeta - \\gamma) + \\gamma, 0, 1\\big)$ равняется 0. Если таких нет или очень мало, то можно выбросить те, которые близки к нулю, а затем дообучить модель без этих голов.\n",
    "\n",
    "\n",
    "[Тут](https://arxiv.org/pdf/2110.03252.pdf) можно почитать про дополнительные хаки для этого метода.\\\n",
    "\\\n",
    "P. S. Заводится тяжело, но заводится. Если гейты не начинают зануляться, то, возможно, вы недостаточно долго учите.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e2b5c8",
   "metadata": {
    "cellId": "nd5ff6484qgfn82w6o6wac",
    "execution_id": "797b6bcf-7917-4dfd-89a1-40a501e470f7"
   },
   "source": [
    "Помимо всего, что написано выше, на просторах интернета можно найти кучу других способов уменьшения модели, не стестяйтесь их искать. При проведении экспериментов старайтесь делать одно изменение за раз и не бросайтесь реализовывать сложный метод, если у вас нет достаточных оснований полагать, что он даст значительный буст.\n",
    "\n",
    "Удачи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de43836",
   "metadata": {
    "cellId": "x2ih17mz36706harys29ao"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "911e67a2-c133-4c44-be8d-8dbd9b857d4b",
  "notebookPath": "hw4.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
